{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8cc72c-7e5b-48b2-b838-d97f96243a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Analysis_12_30_21_Colorado_Fire_segments.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d384bf03-b360-43f9-a1a5-51cc2923565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from helpers.utils import read_docx_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f868fffd-a0ed-4244-933d-bf1fc8756b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_docx_to_dict(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fb858c-b020-4ad7-b81f-b757a56f9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03cddec-d58c-4a51-b70f-ec97bddc11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bad8898-5d43-490e-86b8-23ee2dbe2ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>location</th>\n",
       "      <th>station</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-30 6:14 PM</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>KTVX</td>\n",
       "      <td>u.s. many of these travel troubles will likely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-30 6:12 PM</td>\n",
       "      <td>Phoenix (Prescott)</td>\n",
       "      <td>KNXV</td>\n",
       "      <td>500, 80 homes and businesses destroyed. it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-30 6:03 PM</td>\n",
       "      <td>Phoenix (Prescott)</td>\n",
       "      <td>KNXV</td>\n",
       "      <td>reporting live from downtown flagstaff. luzdel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-30 6:00 PM</td>\n",
       "      <td>San Francisco-Oak-San Jose</td>\n",
       "      <td>KGO</td>\n",
       "      <td>injured. the sheriff did not rule out the poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-30 5:54 PM</td>\n",
       "      <td>Tampa-St. Pete (Sarasota)</td>\n",
       "      <td>WFTS</td>\n",
       "      <td>need this time. it's outside gambling groups a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time                    location station  \\\n",
       "0  2021-12-30 6:14 PM              Salt Lake City    KTVX   \n",
       "1  2021-12-30 6:12 PM          Phoenix (Prescott)    KNXV   \n",
       "2  2021-12-30 6:03 PM          Phoenix (Prescott)    KNXV   \n",
       "3  2021-12-30 6:00 PM  San Francisco-Oak-San Jose     KGO   \n",
       "4  2021-12-30 5:54 PM   Tampa-St. Pete (Sarasota)    WFTS   \n",
       "\n",
       "                                                text  \n",
       "0  u.s. many of these travel troubles will likely...  \n",
       "1  500, 80 homes and businesses destroyed. it is ...  \n",
       "2  reporting live from downtown flagstaff. luzdel...  \n",
       "3  injured. the sheriff did not rule out the poss...  \n",
       "4  need this time. it's outside gambling groups a...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b5f58b2-a437-4abe-84f2-0d717dd7485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from helpers.utils import check_text_likeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529cad2-6033-4bd7-a281-4039bcdcc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['matches'] = df.apply(lambda row: check_text_likeness(df, row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af4e2e-0658-480b-bbec-51e6b26bb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.utils import fetch_biggest_text, mark_use_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acde08-ca8c-487c-9ccd-dd73da946c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['row_to_use'] = df.apply(lambda row: fetch_biggest_text(row['matches']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60950ce-6f9a-4b22-bd8b-d759f71259f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf96813-4283-40e3-9c95-469d7f018f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_use_row(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96a769-f143-46ef-baf6-ea7956f56a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512af26-564a-44a1-b113-751b8b9333d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df['text'].str.lower().str.replace(',', '').str.replace('>', '').str.replace('.', '').str.replace('\\n', '').str.replace('â€™', \"'\").str.replace(\n",
    "    '!', '').str.replace('?', '').str.replace('%', '').str.replace(')', '').str.replace('(', '').str.replace('_', '').str.replace(':', '').str.strip().str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895de87-db1c-4f10-ba2a-05d56cb87e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87bc4b2-3175-4a85-8c89-2a82528920a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f96f0-a776-4778-ab3e-6b29b8f74905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.utils import parse_words\n",
    "df['clean_words'] = df.apply(lambda row: parse_words(row['words']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b69ca-4e76-4ad9-96c7-b4f4c5afc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47592d97-fa56-4662-a032-3cb479c49bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135baa9-c3c3-44a4-a75a-9103abd0a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.utils import fetch_climate_words_in_words, fetch_climate_phrases_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43d3b8-225f-4f29-83d7-e34ef61b3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_climate_words_in_words([\"adapt\",\"for\", \"climate\", \"change\"])\n",
    "# segment_df['climate_words_found'] = segment_df.apply(lambda row: fetch_climate_words_in_text(row['clean_words']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d738399-d5bd-4bc8-adfb-5f4f9acbe6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_climate_phrases_in_text(\"adapt for climate change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d6518-7358-4697-b698-fa0e7311c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['climate_words_found'] = df.apply(lambda row: fetch_climate_words_in_words(row['clean_words']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9326a4-053f-4f6d-837c-865a3b7ab775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ba0fd-2f49-4add-9487-373939b080e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['climate_phrases_found'] = df.apply(lambda row: fetch_climate_phrases_in_text(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95ff39-a630-476a-b2ec-16dff7f41703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee4da9-a149-4cd9-88e2-dc6cd8479e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to csv\n",
    "df.to_csv('reports/abc_all.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065656c-6bf3-4961-8a94-6eb04201a303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683e91f-1361-4af6-9bd3-e356b4be1ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00113b70-1aad-45c7-adb7-b17fe6a6cec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0a0fd-20f7-4639-ba71-7c38f4b8471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = df[df['use_row']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6749a-fc15-4377-852b-ca9066a9f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee88f7a-3d83-40ef-999b-249bfd9377d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = unique_df['clean_words'].str.len().sum()\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737b741-4e5d-4ef5-a943-60cf99384f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_found_master_list(df_clean_words):\n",
    "    \"\"\"Given a column of words, aggregate master list\"\"\"\n",
    "    words_found = list()\n",
    "    for chunk in df_clean_words:\n",
    "        words_found += chunk\n",
    "\n",
    "    return words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c30a84-8856-4e96-81d8-f0d33ac201c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_found = words_found_master_list(unique_df['clean_words'])\n",
    "len(words_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78c8aa-06e5-4686-a263-f3ef077996d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "def master_stopwords_list():\n",
    "    \"\"\"Creates a master list of stopwords from pre-existing stopwords found in nltk and wordcloud\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    final_stopwords = list(STOPWORDS) + list(stop_words)\n",
    "    return [i.lower() for i in set(final_stopwords)]\n",
    "\n",
    "def lemmatize_words(words):\n",
    "    \"\"\"Given a list of words, distill to root words\"\"\"\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    lemma_list = []\n",
    "    for word, tag in pos_tag(words):\n",
    "        wntag = tag[0].lower()\n",
    "        wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "        if not wntag:\n",
    "            lemma = word\n",
    "        else:\n",
    "            lemma = lem.lemmatize(word, pos=wntag)\n",
    "        lemma_list.append(lemma)\n",
    "    return lemma_list\n",
    "\n",
    "def clean_lemmatized_words(lemma_words):\n",
    "    \"\"\"Removes stop words from the lemma list\"\"\"\n",
    "    nonstop_lemma_words = []\n",
    "    final_stopwords = master_stopwords_list()\n",
    "\n",
    "    for word in lemma_words:\n",
    "        if word not in final_stopwords:\n",
    "            nonstop_lemma_words.append(word)\n",
    "\n",
    "    return list(filter(None, nonstop_lemma_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a987f-7ca9-4f50-8217-9e7c69540ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lemma_words = clean_lemmatized_words(lemmatize_words(words_found))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8632540d-1bb5-405a-b69b-7936707790b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "lfdist = FreqDist(clean_lemma_words)\n",
    "lfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb54c1d-3da4-4aed-9871-cd3208beaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lfdist.plot(30,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a19ad8-9f5f-42cf-84eb-a7272f225b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = master_stopwords_list()).generate_from_frequencies(lfdist)\n",
    "\n",
    "# Plot\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('word_cloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2313ec1-ce01-4dd0-98f8-fcec5c23cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 500\n",
    "words_df = pd.DataFrame(lfdist.items(), columns=['Word', 'Count'])\n",
    "\n",
    "words_df.sort_values(by=['Count'], ascending=False, inplace=True)\n",
    "len(words_df)\n",
    "# 1374 total words\n",
    "\n",
    "words_df['Count'].sum()\n",
    "\n",
    "# create data\n",
    "climate_change_words_df = words_df.loc[words_df['Word'].isin(CLIMATE_CHANGE_RELATED_WORDS)]\n",
    "\n",
    "climate_words_count = climate_change_words_df['Count'].sum()\n",
    "non_climate_words_count = words_df['Count'].sum() - climate_words_count\n",
    "\n",
    "comparison_df = pd.DataFrame({'Words': ['Climate-related', 'Non Climate-related'],\n",
    "                             'counts': [climate_words_count, non_climate_words_count]})\n",
    "comparison_df.set_index('Words', inplace=True)\n",
    "print(comparison_df)\n",
    "\n",
    "plot = comparison_df.plot.pie(y='counts', title=\"Climated-related vs non climated-related word frequencies\", legend=True, autopct='%1.1f%%', shadow=True, figsize=(8, 8))\n",
    "\n",
    "fig = plot.get_figure()\n",
    "#fig.savefig(\"comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94a333-ccac-4388-932b-db04ac59d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find climate related word frequencies\n",
    "\n",
    "# set figure size\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# plot horizontal bar plot\n",
    "climate_change_words_df.sort_values(by='Count').plot.barh(x=\"Word\", y=\"Count\", ax=ax)\n",
    "# set the title\n",
    "plt.title(\"Count of climate change related words\")\n",
    "\n",
    "for i, v in enumerate(climate_change_words_df['Count'].sort_values()):\n",
    "    ax.text(v, i , str(v),\n",
    "            color = 'blue', fontweight = 'bold')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('climate-related-words-breakdown.png', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840975d-5190-45be-ad5e-53b02ff0b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find segments\n",
    "climate_change_words_found = list(climate_change_words_df['Word'].unique())\n",
    "climate_change_words_found\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765949a-c2ee-4a87-a608-39c0646caf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df[unique_df[\"climate_words_found\"].str.len() != 0].to_csv('reports/abc_final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44a3a7-b324-4e96-9a81-851e38405c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92856b-9496-41d4-89a3-f4abcf8f05f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
